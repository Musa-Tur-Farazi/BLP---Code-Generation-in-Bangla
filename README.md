# ğŸ¯ BLP25 Bangla-to-Code Generation

**Official Task**: Generate Python functions from Bangla instructions  
**Evaluation**: Pass@1 (percentage of test cases that pass)  
**Deadline**: September 29, 2025

## **ğŸ“ Project Structure**

```
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ OFFICIAL_TASK_GUIDE.md      # Complete guide with commands
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ trial.csv                   # Training data (with solutions)
â”œâ”€â”€ dev_v2.csv                  # Development data (no solutions)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.json              # Converted training data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ research_model.py       # Custom dual-stream architecture
â”‚   â”œâ”€â”€ research_training.py    # Training script
â”‚   â”œâ”€â”€ official_approach.py    # Generate submission
â”‚   â”œâ”€â”€ convert_csv_to_json.py  # Data conversion
â”‚   â”œâ”€â”€ data_utils.py           # Data utilities
â”‚   â””â”€â”€ prompting.py            # Prompt templates
â””â”€â”€ outputs/                    # Trained models
```

## **ğŸš€ Quick Start**

### **1. Setup Environment**
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### **2. Prepare Data**
```bash
python -m src.convert_csv_to_json --input_csv trial.csv --output_json data/train.json
```

### **3. Train Model**
```bash
python -m src.research_training `
  --train_json data/train.json `
  --model_size small `
  --use_dual_stream `
  --num_epochs 10 `
  --output_dir outputs/research_model
```

### **4. Generate Submission**
```bash
python -m src.official_approach `
  --model_path outputs/research_model/latest_model `
  --dev_csv dev_v2.csv `
  --create_zip
```

### **5. Submit to CodaBench**
Upload `submission.zip` to the dev phase.

## **ğŸ”¬ Research Model**

**Novel Dual-Stream Architecture:**
- **Instruction Stream**: Bangla language processing
- **Code Stream**: Python function generation
- **Cross-Attention**: Bidirectional information flow
- **Code-Aware Attention**: Syntax-aware mechanisms

**Expected Performance:** 60-80% Pass@1 (vs 10-20% baseline)

## **ğŸ“Š Model Sizes**

| Size | Parameters | Training Time | Use Case |
|------|------------|---------------|----------|
| Tiny | ~2M | 5 min | Quick test |
| Small | ~15M | 15 min | Development |
| Medium | ~50M | 30 min | Production |

## **ğŸ“ Submission Format**

```json
[
  {
    "id": 1,
    "response": "```python\ndef function_name(...):\n    # implementation\n    return result\n```"
  }
]
```

## **ğŸ”— Resources**

- **Official Task**: https://noshinulfat.github.io/blp25_code_generation_task/
- **CodaBench**: https://codalab.lisn.upsaclay.fr/competitions/
- **Complete Guide**: See `OFFICIAL_TASK_GUIDE.md`

---

**ğŸ¯ This project implements a novel dual-stream architecture for Bangla-to-Python code generation, combining research innovation with official task compatibility.**
